{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T17:15:20.070853Z",
     "iopub.status.busy": "2026-01-29T17:15:20.070235Z",
     "iopub.status.idle": "2026-01-29T18:42:08.955303Z",
     "shell.execute_reply": "2026-01-29T18:42:08.954606Z",
     "shell.execute_reply.started": "2026-01-29T17:15:20.070824Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 17:15:36.709056: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769706936.903692      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1769706936.958986      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1769706937.422881      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769706937.422929      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769706937.422932      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769706937.422934      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Emotion Labels: {'angry': 0, 'happy': 1, 'hesitant': 2, 'interested': 3, 'neutral': 4}\n",
      "üìä Number of classes: 5\n",
      "\n",
      "üìÇ Loading data from: /kaggle/input/emotions-dataset/Emotions\n",
      "  angry: 499 files\n",
      "  happy: 500 files\n",
      "  hesitant: 502 files\n",
      "  interested: 498 files\n",
      "  neutral: 500 files\n",
      "\n",
      "‚úÖ Total samples loaded: 2499\n",
      "\n",
      "üìä Dataset splits:\n",
      "  Train: 1749 samples\n",
      "  Validation: 375 samples\n",
      "  Test: 375 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b04a79095124b8693e82d2995237ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Preprocessing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf0958a3e53476d874572b7a442c7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181335858cd64fa4b315a44c2d157d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92eb2966aaee4ba2b20d67341d682be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Preprocessing complete!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9620aa9987ef4d2fae85261d431d8183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ff3f432a0f4f52b1b89f2a1ffa5afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f7ef30dec3457fac077352c498bb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-xls-r-300m and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Model loaded: facebook/wav2vec2-xls-r-300m\n",
      "üìä Number of parameters: 315,702,405\n",
      "\n",
      "üöÄ Starting training...\n",
      "‚è±Ô∏è  Epochs: 15\n",
      "üì¶ Batch size: 4\n",
      "üìà Learning rate: 2e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3285' max='3285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3285/3285 1:24:32, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.602900</td>\n",
       "      <td>1.599049</td>\n",
       "      <td>0.197333</td>\n",
       "      <td>0.070883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.356900</td>\n",
       "      <td>1.230649</td>\n",
       "      <td>0.597333</td>\n",
       "      <td>0.548685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.908100</td>\n",
       "      <td>0.799255</td>\n",
       "      <td>0.749333</td>\n",
       "      <td>0.710771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.798300</td>\n",
       "      <td>0.646883</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.788147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.577300</td>\n",
       "      <td>0.502910</td>\n",
       "      <td>0.810667</td>\n",
       "      <td>0.802229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.533400</td>\n",
       "      <td>0.517490</td>\n",
       "      <td>0.805333</td>\n",
       "      <td>0.804103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.514800</td>\n",
       "      <td>0.561902</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.786075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.387700</td>\n",
       "      <td>0.567250</td>\n",
       "      <td>0.762667</td>\n",
       "      <td>0.761251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.215400</td>\n",
       "      <td>0.358186</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.880687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.391238</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.870476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.261500</td>\n",
       "      <td>0.428890</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.857796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.381088</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.889357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.209500</td>\n",
       "      <td>0.394719</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.902359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.211200</td>\n",
       "      <td>0.380860</td>\n",
       "      <td>0.898667</td>\n",
       "      <td>0.899698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.384556</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.902327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training complete!\n",
      "\n",
      "üìä Evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL TEST RESULTS\n",
      "============================================================\n",
      "eval_loss: 0.4150\n",
      "eval_accuracy: 0.8613\n",
      "eval_f1: 0.8641\n",
      "eval_runtime: 36.5548\n",
      "eval_samples_per_second: 10.2590\n",
      "eval_steps_per_second: 1.2860\n",
      "epoch: 15.0000\n",
      "============================================================\n",
      "\n",
      "üíæ Model saved to: ./emotion-recognition-model/final\n",
      "\n",
      "üéâ All done! Your emotion recognition model is ready!\n"
     ]
    }
   ],
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# COMPLETE EMOTION RECOGNITION TRAINING\n",
    "# Using Your emotions-dataset\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    Wav2Vec2ForSequenceClassification,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CONFIGURATION\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "MODEL_NAME = \"facebook/wav2vec2-xls-r-300m\"\n",
    "OUTPUT_DIR = \"./emotion-recognition-model\"\n",
    "NUM_EPOCHS = 15\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "MAX_LENGTH = 5 * 16000  # 5 seconds at 16kHz\n",
    "\n",
    "# Emotion labels based on your dataset structure\n",
    "EMOTION_LABELS = {\n",
    "    \"angry\": 0,\n",
    "    \"happy\": 1,\n",
    "    \"hesitant\": 2,\n",
    "    \"interested\": 3,\n",
    "    \"neutral\": 4\n",
    "}\n",
    "\n",
    "LABEL_TO_ID = EMOTION_LABELS\n",
    "ID_TO_LABEL = {v: k for k, v in EMOTION_LABELS.items()}\n",
    "\n",
    "print(f\"üéØ Emotion Labels: {EMOTION_LABELS}\")\n",
    "print(f\"üìä Number of classes: {len(EMOTION_LABELS)}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# DATA LOADING\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def load_audio_file(file_path, target_sr=16000):\n",
    "    \"\"\"Load and preprocess audio file\"\"\"\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=target_sr)\n",
    "        return audio\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_dataset_from_folders(base_path):\n",
    "    \"\"\"\n",
    "    Load dataset from your Kaggle folder structure:\n",
    "    /kaggle/input/emotions-dataset/Emotions/Angry/*.wav\n",
    "    /kaggle/input/emotions-dataset/Emotions/Happy/*.wav\n",
    "    etc.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    emotions_path = base_path / \"Emotions\"\n",
    "    \n",
    "    print(f\"\\nüìÇ Loading data from: {emotions_path}\")\n",
    "    \n",
    "    # Map folder names to standardized emotion labels\n",
    "    folder_to_emotion = {\n",
    "        \"Angry\": \"angry\",\n",
    "        \"Happy\": \"happy\",\n",
    "        \"Hesitant\": \"hesitant\",\n",
    "        \"Interested\": \"interested\",\n",
    "        \"Neutral\": \"neutral\"\n",
    "    }\n",
    "    \n",
    "    for folder_name, emotion in folder_to_emotion.items():\n",
    "        emotion_folder = emotions_path / folder_name\n",
    "        \n",
    "        if not emotion_folder.exists():\n",
    "            print(f\"‚ö†Ô∏è  Warning: {emotion_folder} not found!\")\n",
    "            continue\n",
    "        \n",
    "        # Find all audio files (wav, mp3, etc.)\n",
    "        audio_files = list(emotion_folder.glob(\"*.wav\")) + \\\n",
    "                     list(emotion_folder.glob(\"*.mp3\")) + \\\n",
    "                     list(emotion_folder.glob(\"*.m4a\"))\n",
    "        \n",
    "        print(f\"  {emotion}: {len(audio_files)} files\")\n",
    "        \n",
    "        for audio_file in audio_files:\n",
    "            data.append({\n",
    "                \"path\": str(audio_file),\n",
    "                \"emotion\": emotion,\n",
    "                \"label\": EMOTION_LABELS[emotion]\n",
    "            })\n",
    "    \n",
    "    print(f\"\\n‚úÖ Total samples loaded: {len(data)}\")\n",
    "    return data\n",
    "\n",
    "# Load your dataset\n",
    "DATASET_PATH = Path(\"/kaggle/input/emotions-dataset\")\n",
    "all_data = load_dataset_from_folders(DATASET_PATH)\n",
    "\n",
    "# Split into train/val/test\n",
    "train_data, temp_data = train_test_split(all_data, test_size=0.3, random_state=42, stratify=[d[\"label\"] for d in all_data])\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=[d[\"label\"] for d in temp_data])\n",
    "\n",
    "print(f\"\\nüìä Dataset splits:\")\n",
    "print(f\"  Train: {len(train_data)} samples\")\n",
    "print(f\"  Validation: {len(val_data)} samples\")\n",
    "print(f\"  Test: {len(test_data)} samples\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# FEATURE EXTRACTION\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"Process audio files for the model\"\"\"\n",
    "    audio_arrays = []\n",
    "    \n",
    "    for path in examples[\"path\"]:\n",
    "        audio = load_audio_file(path)\n",
    "        if audio is not None:\n",
    "            # Pad or truncate to MAX_LENGTH\n",
    "            if len(audio) > MAX_LENGTH:\n",
    "                audio = audio[:MAX_LENGTH]\n",
    "            else:\n",
    "                audio = np.pad(audio, (0, MAX_LENGTH - len(audio)))\n",
    "            audio_arrays.append(audio)\n",
    "        else:\n",
    "            # If file fails to load, use silence\n",
    "            audio_arrays.append(np.zeros(MAX_LENGTH))\n",
    "    \n",
    "    # Extract features\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays,\n",
    "        sampling_rate=16000,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"input_values\": inputs.input_values,\n",
    "        \"labels\": examples[\"label\"]\n",
    "    }\n",
    "\n",
    "# Create HuggingFace datasets\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "test_dataset = Dataset.from_list(test_data)\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"\\nüîÑ Preprocessing datasets...\")\n",
    "dataset_dict = dataset_dict.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=8,\n",
    "    remove_columns=[\"path\", \"emotion\"]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Preprocessing complete!\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# MODEL SETUP\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(EMOTION_LABELS),\n",
    "    label2id=LABEL_TO_ID,\n",
    "    id2label=ID_TO_LABEL,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# Freeze feature extractor\n",
    "model.freeze_feature_encoder()\n",
    "\n",
    "print(f\"\\nü§ñ Model loaded: {MODEL_NAME}\")\n",
    "print(f\"üìä Number of parameters: {model.num_parameters():,}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# TRAINING CONFIGURATION\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute accuracy and F1 score\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    "    fp16=True,  # Use mixed precision for faster training\n",
    "    save_total_limit=2,\n",
    "    report_to=[\"tensorboard\"]\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_dict[\"train\"],\n",
    "    eval_dataset=dataset_dict[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Starting training...\")\n",
    "print(f\"‚è±Ô∏è  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"üì¶ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"üìà Learning rate: {LEARNING_RATE}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# TRAIN THE MODEL\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# EVALUATION\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\nüìä Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(dataset_dict[\"test\"])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL TEST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "for key, value in test_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# SAVE MODEL\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final_model_path = f\"{OUTPUT_DIR}/final\"\n",
    "trainer.save_model(final_model_path)\n",
    "feature_extractor.save_pretrained(final_model_path)\n",
    "\n",
    "print(f\"\\nüíæ Model saved to: {final_model_path}\")\n",
    "print(\"\\nüéâ All done! Your emotion recognition model is ready!\")\n",
    " \"\"\"\n",
    "Check if your model was saved correctly\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Checking model directory...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check main model directory\n",
    "model_dir = Path(\"/kaggle/working/emotion-recognition-model\")\n",
    "\n",
    "if model_dir.exists():\n",
    "    print(f\"‚úÖ Directory exists: {model_dir}\")\n",
    "    print(f\"\\nContents of {model_dir}:\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    for item in sorted(model_dir.iterdir()):\n",
    "        if item.is_dir():\n",
    "            print(f\"  üìÅ {item.name}/\")\n",
    "            # Check subdirectories\n",
    "            for subitem in sorted(item.iterdir())[:5]:  # Show first 5 items\n",
    "                print(f\"     - {subitem.name}\")\n",
    "            if len(list(item.iterdir())) > 5:\n",
    "                print(f\"     ... and {len(list(item.iterdir())) - 5} more files\")\n",
    "        else:\n",
    "            size = item.stat().st_size / (1024 * 1024)  # Size in MB\n",
    "            print(f\"  üìÑ {item.name} ({size:.2f} MB)\")\n",
    "    \n",
    "    # Check for required files\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Checking for required model files:\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    required_files = [\n",
    "        \"config.json\",\n",
    "        \"preprocessor_config.json\",\n",
    "        \"model.safetensors\",  # or pytorch_model.bin\n",
    "    ]\n",
    "    \n",
    "    for file in required_files:\n",
    "        file_path = model_dir / file\n",
    "        if file_path.exists():\n",
    "            print(f\"  ‚úÖ {file}\")\n",
    "        else:\n",
    "            # Check alternative names\n",
    "            if file == \"model.safetensors\":\n",
    "                alt_path = model_dir / \"pytorch_model.bin\"\n",
    "                if alt_path.exists():\n",
    "                    print(f\"  ‚úÖ pytorch_model.bin (alternative)\")\n",
    "                else:\n",
    "                    print(f\"  ‚ùå {file} (MISSING!)\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå {file} (MISSING!)\")\n",
    "    \n",
    "    # Check if there's a 'final' subdirectory\n",
    "    final_dir = model_dir / \"final\"\n",
    "    if final_dir.exists():\n",
    "        print(f\"\\n‚úÖ Found 'final' subdirectory!\")\n",
    "        print(f\"\\nContents of {final_dir}:\")\n",
    "        print(\"-\"*60)\n",
    "        for item in sorted(final_dir.iterdir()):\n",
    "            if item.is_file():\n",
    "                size = item.stat().st_size / (1024 * 1024)\n",
    "                print(f\"  üìÑ {item.name} ({size:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  No 'final' subdirectory found\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Directory does NOT exist: {model_dir}\")\n",
    "    print(\"\\n‚ö†Ô∏è  This means the model was NOT saved!\")\n",
    "    print(\"\\nPossible reasons:\")\n",
    "    print(\"  1. Training did not complete successfully\")\n",
    "    print(\"  2. Training is still running\")\n",
    "    print(\"  3. Model was saved to a different location\")\n",
    "    \n",
    "    # Check working directory\n",
    "    print(f\"\\nChecking /kaggle/working/ directory:\")\n",
    "    print(\"-\"*60)\n",
    "    working_dir = Path(\"/kaggle/working\")\n",
    "    if working_dir.exists():\n",
    "        for item in sorted(working_dir.iterdir()):\n",
    "            if item.is_dir():\n",
    "                print(f\"  üìÅ {item.name}/\")\n",
    "            else:\n",
    "                size = item.stat().st_size / (1024 * 1024)\n",
    "                print(f\"  üìÑ {item.name} ({size:.2f} MB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONCLUSION:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_path = Path(\"/kaggle/working/emotion-recognition-model\")\n",
    "final_path = model_path / \"final\"\n",
    "\n",
    "if final_path.exists() and (final_path / \"config.json\").exists():\n",
    "    print(\"‚úÖ Model appears to be saved correctly!\")\n",
    "    print(f\"   Use this path: {final_path}\")\n",
    "elif model_path.exists() and (model_path / \"config.json\").exists():\n",
    "    print(\"‚úÖ Model is saved in main directory!\")\n",
    "    print(f\"   Use this path: {model_path}\")\n",
    "else:\n",
    "    print(\"‚ùå Model was NOT saved properly!\")\n",
    "    print(\"   You need to run the training script again.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "Test 10 Voice Notes from Each Emotion Category\n",
    "This script samples 10 VNs from each emotion (angry, happy, hesitant, interested, neutral)\n",
    "and evaluates them using your trained model.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CONFIGURATION\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "MODEL_PATH = \"./emotion-recognition-model/final\"  # Update this path if needed\n",
    "DATASET_PATH = Path(\"/kaggle/input/emotions-dataset\")  # Update this path if needed\n",
    "MAX_LENGTH = 5 * 16000  # 5 seconds at 16kHz\n",
    "SAMPLES_PER_EMOTION = 10\n",
    "\n",
    "# Emotion labels\n",
    "EMOTION_LABELS = {\n",
    "    \"angry\": 0,\n",
    "    \"happy\": 1,\n",
    "    \"hesitant\": 2,\n",
    "    \"interested\": 3,\n",
    "    \"neutral\": 4\n",
    "}\n",
    "\n",
    "ID_TO_LABEL = {v: k for k, v in EMOTION_LABELS.items()}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TESTING 10 VNs FROM EACH EMOTION CATEGORY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# LOAD MODEL\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\nüì¶ Loading model and feature extractor...\")\n",
    "try:\n",
    "    model = Wav2Vec2ForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(MODEL_PATH)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"‚úÖ Model loaded successfully on {device}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    print(\"\\nMake sure you've trained the model first and MODEL_PATH is correct!\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# LOAD AUDIO SAMPLES\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def load_audio_file(file_path, target_sr=16000):\n",
    "    \"\"\"Load and preprocess audio file\"\"\"\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=target_sr)\n",
    "        return audio\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_samples_per_emotion(base_path, samples_per_emotion=10):\n",
    "    \"\"\"\n",
    "    Sample 10 audio files from each emotion folder\n",
    "    \"\"\"\n",
    "    emotions_path = base_path / \"Emotions\"\n",
    "    \n",
    "    # Map folder names to standardized emotion labels\n",
    "    folder_to_emotion = {\n",
    "        \"Angry\": \"angry\",\n",
    "        \"Happy\": \"happy\",\n",
    "        \"Hesitant\": \"hesitant\",\n",
    "        \"Interested\": \"interested\",\n",
    "        \"Neutral\": \"neutral\"\n",
    "    }\n",
    "    \n",
    "    test_samples = []\n",
    "    \n",
    "    print(f\"\\nüìÇ Sampling {samples_per_emotion} files from each emotion folder...\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for folder_name, emotion in folder_to_emotion.items():\n",
    "        emotion_folder = emotions_path / folder_name\n",
    "        \n",
    "        if not emotion_folder.exists():\n",
    "            print(f\"‚ö†Ô∏è  Warning: {emotion_folder} not found!\")\n",
    "            continue\n",
    "        \n",
    "        # Find all audio files\n",
    "        audio_files = list(emotion_folder.glob(\"*.wav\")) + \\\n",
    "                     list(emotion_folder.glob(\"*.mp3\")) + \\\n",
    "                     list(emotion_folder.glob(\"*.m4a\"))\n",
    "        \n",
    "        # Randomly sample files\n",
    "        if len(audio_files) >= samples_per_emotion:\n",
    "            sampled_files = random.sample(audio_files, samples_per_emotion)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Warning: Only {len(audio_files)} files found for {emotion}, using all of them\")\n",
    "            sampled_files = audio_files\n",
    "        \n",
    "        print(f\"  {emotion}: {len(sampled_files)} files sampled\")\n",
    "        \n",
    "        for audio_file in sampled_files:\n",
    "            test_samples.append({\n",
    "                \"path\": str(audio_file),\n",
    "                \"emotion\": emotion,\n",
    "                \"label\": EMOTION_LABELS[emotion],\n",
    "                \"filename\": audio_file.name\n",
    "            })\n",
    "    \n",
    "    print(f\"\\n‚úÖ Total test samples: {len(test_samples)}\")\n",
    "    return test_samples\n",
    "\n",
    "# Load test samples\n",
    "random.seed(42)  # For reproducibility\n",
    "test_samples = get_samples_per_emotion(DATASET_PATH, SAMPLES_PER_EMOTION)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# RUN PREDICTIONS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\nüîÑ Running predictions...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "results_details = []\n",
    "\n",
    "for idx, sample in enumerate(test_samples):\n",
    "    # Load audio\n",
    "    audio = load_audio_file(sample[\"path\"])\n",
    "    \n",
    "    if audio is None:\n",
    "        print(f\"‚ö†Ô∏è  Skipping {sample['filename']} (failed to load)\")\n",
    "        continue\n",
    "    \n",
    "    # Pad or truncate\n",
    "    if len(audio) > MAX_LENGTH:\n",
    "        audio = audio[:MAX_LENGTH]\n",
    "    else:\n",
    "        audio = np.pad(audio, (0, MAX_LENGTH - len(audio)))\n",
    "    \n",
    "    # Extract features\n",
    "    inputs = feature_extractor(\n",
    "        audio,\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    input_values = inputs.input_values.to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "        predicted_id = torch.argmax(logits, dim=-1).item()\n",
    "    \n",
    "    predicted_emotion = ID_TO_LABEL[predicted_id]\n",
    "    true_emotion = sample[\"emotion\"]\n",
    "    \n",
    "    predictions.append(predicted_id)\n",
    "    true_labels.append(sample[\"label\"])\n",
    "    \n",
    "    # Store detailed results\n",
    "    results_details.append({\n",
    "        \"filename\": sample[\"filename\"],\n",
    "        \"true_emotion\": true_emotion,\n",
    "        \"predicted_emotion\": predicted_emotion,\n",
    "        \"correct\": predicted_emotion == true_emotion\n",
    "    })\n",
    "    \n",
    "    # Progress indicator\n",
    "    if (idx + 1) % 10 == 0:\n",
    "        print(f\"  Processed {idx + 1}/{len(test_samples)} samples...\")\n",
    "\n",
    "print(f\"\\n‚úÖ Predictions complete!\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CALCULATE METRICS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OVERALL RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "print(f\"Overall Accuracy: {accuracy:.4f} ({accuracy * 100:.2f}%)\")\n",
    "print(f\"Overall F1 Score: {f1:.4f}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# PER-EMOTION BREAKDOWN\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PER-EMOTION ACCURACY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "emotion_stats = {}\n",
    "for emotion in EMOTION_LABELS.keys():\n",
    "    emotion_results = [r for r in results_details if r[\"true_emotion\"] == emotion]\n",
    "    if emotion_results:\n",
    "        correct = sum(1 for r in emotion_results if r[\"correct\"])\n",
    "        total = len(emotion_results)\n",
    "        accuracy_pct = (correct / total) * 100\n",
    "        emotion_stats[emotion] = {\n",
    "            \"correct\": correct,\n",
    "            \"total\": total,\n",
    "            \"accuracy\": accuracy_pct\n",
    "        }\n",
    "        print(f\"  {emotion.capitalize():12s}: {correct}/{total} correct ({accuracy_pct:.2f}%)\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CONFUSION MATRIX\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "emotion_names = [ID_TO_LABEL[i] for i in range(len(EMOTION_LABELS))]\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\n\" + \" \" * 15 + \"Predicted\")\n",
    "print(\" \" * 12, end=\"\")\n",
    "for name in emotion_names:\n",
    "    print(f\"{name[:8]:>10s}\", end=\"\")\n",
    "print(\"\\nActual\")\n",
    "\n",
    "for i, name in enumerate(emotion_names):\n",
    "    print(f\"{name[:8]:>10s}\", end=\"  \")\n",
    "    for j in range(len(emotion_names)):\n",
    "        print(f\"{cm[i][j]:>10d}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# DETAILED CLASSIFICATION REPORT\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETAILED CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(classification_report(\n",
    "    true_labels, \n",
    "    predictions, \n",
    "    target_names=emotion_names,\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# SAVE DETAILED RESULTS TO CSV\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create DataFrame\n",
    "df_results = pd.DataFrame(results_details)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = \"test_results_10_per_emotion.csv\"\n",
    "df_results.to_csv(output_file, index=False)\n",
    "print(f\"‚úÖ Detailed results saved to: {output_file}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# MISCLASSIFIED SAMPLES (WRONG PREDICTIONS)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"WRONG PREDICTIONS - MODEL ERRORS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "misclassified = df_results[df_results[\"correct\"] == False]\n",
    "if len(misclassified) > 0:\n",
    "    print(f\"\\n‚ùå Total WRONG predictions: {len(misclassified)}/{len(df_results)}\")\n",
    "    print(f\"   Error Rate: {(len(misclassified)/len(df_results)*100):.2f}%\")\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"MODEL WAS WRONG - Here are the mistakes:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for idx, row in misclassified.iterrows():\n",
    "        print(f\"\\n‚ùå File: {row['filename']}\")\n",
    "        print(f\"   ‚û§ Model predicted: {row['predicted_emotion'].upper()} (WRONG!)\")\n",
    "        print(f\"   ‚úì Correct answer was: {row['true_emotion'].upper()}\")\n",
    "        print(f\"   ‚Üí Model confused '{row['true_emotion']}' for '{row['predicted_emotion']}'\")\n",
    "    \n",
    "    # Group errors by confusion type\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ERROR PATTERNS - What the model got confused about\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    error_patterns = {}\n",
    "    for idx, row in misclassified.iterrows():\n",
    "        key = f\"{row['true_emotion']} ‚Üí {row['predicted_emotion']}\"\n",
    "        if key not in error_patterns:\n",
    "            error_patterns[key] = []\n",
    "        error_patterns[key].append(row['filename'])\n",
    "    \n",
    "    for pattern, files in sorted(error_patterns.items(), key=lambda x: len(x[1]), reverse=True):\n",
    "        true_em, pred_em = pattern.split(' ‚Üí ')\n",
    "        print(f\"\\n‚ùå Confused {true_em.upper()} as {pred_em.upper()}: {len(files)} times\")\n",
    "        for file in files:\n",
    "            print(f\"   - {file}\")\n",
    "else:\n",
    "    print(\"\\nüéâ Perfect! No misclassifications!\")\n",
    "    print(\"   The model got ALL predictions correct!\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# SUMMARY\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "correct_predictions = len(df_results) - len(misclassified)\n",
    "print(f\"\\nüìä RESULTS:\")\n",
    "print(f\"   ‚úÖ Correct predictions: {correct_predictions}/{len(test_samples)}\")\n",
    "print(f\"   ‚ùå Wrong predictions: {len(misclassified)}/{len(test_samples)}\")\n",
    "print(f\"   üìà Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"   üìä F1 Score: {f1:.4f}\")\n",
    "\n",
    "if len(misclassified) > 0:\n",
    "    print(f\"\\n‚ùå MODEL MISTAKES RECAP:\")\n",
    "    print(f\"   The model was WRONG on {len(misclassified)} predictions:\")\n",
    "    for idx, row in misclassified.iterrows():\n",
    "        print(f\"   ‚Ä¢ {row['filename'][:35]:35s} - Predicted: {row['predicted_emotion']:10s} | Should be: {row['true_emotion']:10s}\")\n",
    "\n",
    "print(f\"\\nüíæ All results saved to: {output_file}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéâ Testing complete!\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T18:43:00.195237Z",
     "iopub.status.busy": "2026-01-29T18:43:00.194934Z",
     "iopub.status.idle": "2026-01-29T18:43:00.210498Z",
     "shell.execute_reply": "2026-01-29T18:43:00.209817Z",
     "shell.execute_reply.started": "2026-01-29T18:43:00.195214Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking model directory...\n",
      "============================================================\n",
      "‚úÖ Directory exists: /kaggle/working/emotion-recognition-model\n",
      "\n",
      "Contents of /kaggle/working/emotion-recognition-model:\n",
      "------------------------------------------------------------\n",
      "  üìÅ checkpoint-2847/\n",
      "     - config.json\n",
      "     - model.safetensors\n",
      "     - optimizer.pt\n",
      "     - rng_state.pth\n",
      "     - scaler.pt\n",
      "     ... and 3 more files\n",
      "  üìÅ checkpoint-3285/\n",
      "     - config.json\n",
      "     - model.safetensors\n",
      "     - optimizer.pt\n",
      "     - rng_state.pth\n",
      "     - scaler.pt\n",
      "     ... and 3 more files\n",
      "  üìÅ final/\n",
      "     - config.json\n",
      "     - model.safetensors\n",
      "     - preprocessor_config.json\n",
      "     - training_args.bin\n",
      "  üìÅ runs/\n",
      "     - Jan29_17-16-50_d701060de0c2\n",
      "\n",
      "============================================================\n",
      "Checking for required model files:\n",
      "------------------------------------------------------------\n",
      "  ‚ùå config.json (MISSING!)\n",
      "  ‚ùå preprocessor_config.json (MISSING!)\n",
      "  ‚ùå model.safetensors (MISSING!)\n",
      "\n",
      "‚úÖ Found 'final' subdirectory!\n",
      "\n",
      "Contents of /kaggle/working/emotion-recognition-model/final:\n",
      "------------------------------------------------------------\n",
      "  üìÑ config.json (0.00 MB)\n",
      "  üìÑ model.safetensors (1204.36 MB)\n",
      "  üìÑ preprocessor_config.json (0.00 MB)\n",
      "  üìÑ training_args.bin (0.01 MB)\n",
      "\n",
      "============================================================\n",
      "CONCLUSION:\n",
      "============================================================\n",
      "‚úÖ Model appears to be saved correctly!\n",
      "   Use this path: /kaggle/working/emotion-recognition-model/final\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Check if your model was saved correctly\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Checking model directory...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check main model directory\n",
    "model_dir = Path(\"/kaggle/working/emotion-recognition-model\")\n",
    "\n",
    "if model_dir.exists():\n",
    "    print(f\"‚úÖ Directory exists: {model_dir}\")\n",
    "    print(f\"\\nContents of {model_dir}:\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    for item in sorted(model_dir.iterdir()):\n",
    "        if item.is_dir():\n",
    "            print(f\"  üìÅ {item.name}/\")\n",
    "            # Check subdirectories\n",
    "            for subitem in sorted(item.iterdir())[:5]:  # Show first 5 items\n",
    "                print(f\"     - {subitem.name}\")\n",
    "            if len(list(item.iterdir())) > 5:\n",
    "                print(f\"     ... and {len(list(item.iterdir())) - 5} more files\")\n",
    "        else:\n",
    "            size = item.stat().st_size / (1024 * 1024)  # Size in MB\n",
    "            print(f\"  üìÑ {item.name} ({size:.2f} MB)\")\n",
    "    \n",
    "    # Check for required files\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Checking for required model files:\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    required_files = [\n",
    "        \"config.json\",\n",
    "        \"preprocessor_config.json\",\n",
    "        \"model.safetensors\",  # or pytorch_model.bin\n",
    "    ]\n",
    "    \n",
    "    for file in required_files:\n",
    "        file_path = model_dir / file\n",
    "        if file_path.exists():\n",
    "            print(f\"  ‚úÖ {file}\")\n",
    "        else:\n",
    "            # Check alternative names\n",
    "            if file == \"model.safetensors\":\n",
    "                alt_path = model_dir / \"pytorch_model.bin\"\n",
    "                if alt_path.exists():\n",
    "                    print(f\"  ‚úÖ pytorch_model.bin (alternative)\")\n",
    "                else:\n",
    "                    print(f\"  ‚ùå {file} (MISSING!)\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå {file} (MISSING!)\")\n",
    "    \n",
    "    # Check if there's a 'final' subdirectory\n",
    "    final_dir = model_dir / \"final\"\n",
    "    if final_dir.exists():\n",
    "        print(f\"\\n‚úÖ Found 'final' subdirectory!\")\n",
    "        print(f\"\\nContents of {final_dir}:\")\n",
    "        print(\"-\"*60)\n",
    "        for item in sorted(final_dir.iterdir()):\n",
    "            if item.is_file():\n",
    "                size = item.stat().st_size / (1024 * 1024)\n",
    "                print(f\"  üìÑ {item.name} ({size:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  No 'final' subdirectory found\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Directory does NOT exist: {model_dir}\")\n",
    "    print(\"\\n‚ö†Ô∏è  This means the model was NOT saved!\")\n",
    "    print(\"\\nPossible reasons:\")\n",
    "    print(\"  1. Training did not complete successfully\")\n",
    "    print(\"  2. Training is still running\")\n",
    "    print(\"  3. Model was saved to a different location\")\n",
    "    \n",
    "    # Check working directory\n",
    "    print(f\"\\nChecking /kaggle/working/ directory:\")\n",
    "    print(\"-\"*60)\n",
    "    working_dir = Path(\"/kaggle/working\")\n",
    "    if working_dir.exists():\n",
    "        for item in sorted(working_dir.iterdir()):\n",
    "            if item.is_dir():\n",
    "                print(f\"  üìÅ {item.name}/\")\n",
    "            else:\n",
    "                size = item.stat().st_size / (1024 * 1024)\n",
    "                print(f\"  üìÑ {item.name} ({size:.2f} MB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONCLUSION:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_path = Path(\"/kaggle/working/emotion-recognition-model\")\n",
    "final_path = model_path / \"final\"\n",
    "\n",
    "if final_path.exists() and (final_path / \"config.json\").exists():\n",
    "    print(\"‚úÖ Model appears to be saved correctly!\")\n",
    "    print(f\"   Use this path: {final_path}\")\n",
    "elif model_path.exists() and (model_path / \"config.json\").exists():\n",
    "    print(\"‚úÖ Model is saved in main directory!\")\n",
    "    print(f\"   Use this path: {model_path}\")\n",
    "else:\n",
    "    print(\"‚ùå Model was NOT saved properly!\")\n",
    "    print(\"   You need to run the training script again.\")\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "Test Unknown Dataset Voice Notes\n",
    "Testing 3 external VNs: angry.ogg, happy.ogg, netural.ogg\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CONFIGURATION\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "MODEL_PATH = \"./emotion-recognition-model/final\"  # Update this path if needed\n",
    "# Try multiple possible locations for the dataset\n",
    "POSSIBLE_PATHS = [\n",
    "    \"./unknown-dataset\",                              # Local directory\n",
    "    \"/kaggle/input/unknown-datasettt/unknown-dataset\", # Kaggle input\n",
    "    \"/kaggle/working/unknown-dataset\"                 # Kaggle working\n",
    "]\n",
    "\n",
    "# Find the correct path\n",
    "AUDIO_FOLDER = None\n",
    "for path in POSSIBLE_PATHS:\n",
    "    if os.path.exists(path):\n",
    "        AUDIO_FOLDER = path\n",
    "        break\n",
    "\n",
    "if AUDIO_FOLDER is None:\n",
    "    print(\"‚ùå Error: Could not find unknown-dataset folder!\")\n",
    "    print(\"Searched in:\")\n",
    "    for path in POSSIBLE_PATHS:\n",
    "        print(f\"  - {path}\")\n",
    "    exit(1)\n",
    "\n",
    "MAX_LENGTH = 5 * 16000  # 5 seconds at 16kHz\n",
    "\n",
    "# Emotion labels\n",
    "EMOTION_LABELS = {\n",
    "    \"angry\": 0,\n",
    "    \"happy\": 1,\n",
    "    \"hesitant\": 2,\n",
    "    \"interested\": 3,\n",
    "    \"neutral\": 4\n",
    "}\n",
    "\n",
    "ID_TO_LABEL = {v: k for k, v in EMOTION_LABELS.items()}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TESTING UNKNOWN DATASET VOICE NOTES\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nüìç Found dataset at: {AUDIO_FOLDER}\")\n",
    "print(\"\\nüìÇ Dataset files:\")\n",
    "print(\"   1. angry (1).wav\")\n",
    "print(\"   2. happy (1).wav\")\n",
    "print(\"   3. happyb.wav\")\n",
    "print(\"   4. netural.wav (neutral)\")\n",
    "print(\"\\nüéØ Goal: See what the model predicts for each file\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# LOAD MODEL\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\nüì¶ Loading trained model...\")\n",
    "try:\n",
    "    model = Wav2Vec2ForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(MODEL_PATH)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"‚úÖ Model loaded successfully on {device}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    print(\"\\nMake sure:\")\n",
    "    print(\"  1. You've trained the model first\")\n",
    "    print(\"  2. MODEL_PATH is correct\")\n",
    "    print(f\"  3. The model exists at: {MODEL_PATH}\")\n",
    "    exit(1)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# LOAD AUDIO FUNCTION\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def load_audio_file(file_path, target_sr=16000):\n",
    "    \"\"\"Load and preprocess audio file\"\"\"\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=target_sr)\n",
    "        return audio\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# TEST FILES SETUP\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "# Define test files with expected emotion (what the filename suggests)\n",
    "test_files = [\n",
    "    {\"filename\": \"angry (1).wav\", \"expected\": \"angry\"},\n",
    "    {\"filename\": \"happy (1).wav\", \"expected\": \"happy\"},\n",
    "    {\"filename\": \"happyb.wav\", \"expected\": \"happy\"},  # Another happy sample\n",
    "    {\"filename\": \"netural.wav\", \"expected\": \"neutral\"},  # Note: typo in filename\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# PREDICT EMOTION FOR EACH FILE\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RUNNING PREDICTIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, file_info in enumerate(test_files, 1):\n",
    "    filename = file_info[\"filename\"]\n",
    "    expected_emotion = file_info[\"expected\"]\n",
    "    file_path = os.path.join(AUDIO_FOLDER, filename)\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"TESTING FILE {i}/4: {filename}\")\n",
    "    print(f\"Expected emotion (from filename): {expected_emotion.upper()}\")\n",
    "    print('=' * 80)\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"  ‚ùå File not found: {file_path}\")\n",
    "        results.append({\n",
    "            \"filename\": filename,\n",
    "            \"expected\": expected_emotion,\n",
    "            \"status\": \"FILE NOT FOUND\",\n",
    "            \"predicted_emotion\": \"N/A\",\n",
    "            \"confidence\": 0.0,\n",
    "            \"correct\": False\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    # Load audio\n",
    "    print(\"  üì• Loading audio file...\")\n",
    "    audio = load_audio_file(file_path)\n",
    "    \n",
    "    if audio is None:\n",
    "        print(f\"  ‚ùå FAILED to load this file. Skipping...\")\n",
    "        results.append({\n",
    "            \"filename\": filename,\n",
    "            \"expected\": expected_emotion,\n",
    "            \"status\": \"FAILED TO LOAD\",\n",
    "            \"predicted_emotion\": \"N/A\",\n",
    "            \"confidence\": 0.0,\n",
    "            \"correct\": False\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    print(f\"  ‚úÖ Audio loaded successfully\")\n",
    "    print(f\"  ‚è±Ô∏è  Duration: {len(audio)/16000:.2f} seconds\")\n",
    "    \n",
    "    # Pad or truncate\n",
    "    if len(audio) > MAX_LENGTH:\n",
    "        print(f\"  ‚úÇÔ∏è  Audio is longer than 5 seconds, truncating...\")\n",
    "        audio = audio[:MAX_LENGTH]\n",
    "    else:\n",
    "        audio = np.pad(audio, (0, MAX_LENGTH - len(audio)))\n",
    "    \n",
    "    # Extract features\n",
    "    print(\"  üîÑ Extracting audio features...\")\n",
    "    inputs = feature_extractor(\n",
    "        audio,\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    input_values = inputs.input_values.to(device)\n",
    "    \n",
    "    # Predict\n",
    "    print(\"  ü§ñ Running model prediction...\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        predicted_id = torch.argmax(logits, dim=-1).item()\n",
    "        confidence = probabilities[0][predicted_id].item()\n",
    "    \n",
    "    predicted_emotion = ID_TO_LABEL[predicted_id]\n",
    "    \n",
    "    # Get all probabilities\n",
    "    all_probs = {ID_TO_LABEL[j]: probabilities[0][j].item() for j in range(len(EMOTION_LABELS))}\n",
    "    \n",
    "    # Check if prediction matches expected\n",
    "    is_correct = (predicted_emotion == expected_emotion)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n  \" + \"üéØ PREDICTION RESULT \".center(76, \"‚îÄ\"))\n",
    "    print(f\"\\n  üìã Expected (from filename): {expected_emotion.upper()}\")\n",
    "    print(f\"  üîÆ MODEL PREDICTS: {predicted_emotion.upper()}\")\n",
    "    print(f\"  üìä Confidence: {confidence * 100:.2f}%\")\n",
    "    \n",
    "    if is_correct:\n",
    "        print(f\"  ‚úÖ CORRECT! Model got it right!\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå WRONG! Model predicted {predicted_emotion.upper()} but expected {expected_emotion.upper()}\")\n",
    "    \n",
    "    print(f\"\\n  üìà All Emotion Probabilities:\")\n",
    "    # Sort by probability\n",
    "    sorted_probs = sorted(all_probs.items(), key=lambda x: x[1], reverse=True)\n",
    "    for emotion, prob in sorted_probs:\n",
    "        bar_length = int(prob * 50)\n",
    "        bar = \"‚ñà\" * bar_length + \"‚ñë\" * (50 - bar_length)\n",
    "        marker = \"üëà PREDICTED\" if emotion == predicted_emotion else \"\"\n",
    "        if emotion == expected_emotion and emotion != predicted_emotion:\n",
    "            marker = \"‚Üê EXPECTED\"\n",
    "        elif emotion == expected_emotion and emotion == predicted_emotion:\n",
    "            marker = \"üëà PREDICTED (CORRECT!)\"\n",
    "        print(f\"     {emotion.capitalize():12s} {prob*100:6.2f}% ‚îÇ{bar}‚îÇ {marker}\")\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"filename\": filename,\n",
    "        \"expected\": expected_emotion,\n",
    "        \"status\": \"SUCCESS\",\n",
    "        \"predicted_emotion\": predicted_emotion,\n",
    "        \"confidence\": confidence * 100,\n",
    "        \"correct\": is_correct,\n",
    "        \"all_probabilities\": all_probs\n",
    "    })\n",
    "    \n",
    "    print()\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# SUMMARY OF PREDICTIONS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY - PREDICTION RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "successful = [r for r in results if r[\"status\"] == \"SUCCESS\"]\n",
    "correct_predictions = [r for r in successful if r[\"correct\"]]\n",
    "wrong_predictions = [r for r in successful if not r[\"correct\"]]\n",
    "\n",
    "print(f\"\\n‚úÖ Successfully tested: {len(successful)}/4 files\")\n",
    "print(f\"‚úÖ Correct predictions: {len(correct_predictions)}/{len(successful)}\")\n",
    "print(f\"‚ùå Wrong predictions: {len(wrong_predictions)}/{len(successful)}\")\n",
    "\n",
    "if len(successful) > 0:\n",
    "    accuracy = (len(correct_predictions) / len(successful)) * 100\n",
    "    print(f\"üìä Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Show all predictions\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"DETAILED RESULTS\")\n",
    "print('=' * 80)\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    if result['status'] == 'SUCCESS':\n",
    "        status_icon = \"‚úÖ\" if result['correct'] else \"‚ùå\"\n",
    "        print(f\"\\n{i}. {result['filename']}\")\n",
    "        print(f\"   Expected: {result['expected'].upper()}\")\n",
    "        print(f\"   Predicted: {result['predicted_emotion'].upper()} (Confidence: {result['confidence']:.2f}%)\")\n",
    "        print(f\"   {status_icon} {'CORRECT' if result['correct'] else 'WRONG'}\")\n",
    "    else:\n",
    "        print(f\"\\n{i}. {result['filename']}\")\n",
    "        print(f\"   ‚ùå Status: {result['status']}\")\n",
    "\n",
    "# Show wrong predictions in detail\n",
    "if wrong_predictions:\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"‚ùå MODEL MISTAKES - WRONG PREDICTIONS\")\n",
    "    print('=' * 80)\n",
    "    \n",
    "    for result in wrong_predictions:\n",
    "        print(f\"\\n‚ùå File: {result['filename']}\")\n",
    "        print(f\"   Expected emotion: {result['expected'].upper()}\")\n",
    "        print(f\"   ‚û§ Model predicted: {result['predicted_emotion'].upper()} (WRONG!)\")\n",
    "        print(f\"   ‚úì Correct answer was: {result['expected'].upper()}\")\n",
    "        print(f\"   üìä Model was {result['confidence']:.2f}% confident (but wrong)\")\n",
    "        print(f\"   ‚Üí Model confused '{result['expected']}' for '{result['predicted_emotion']}'\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# SAVE RESULTS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "output_file = \"unknown_dataset_predictions.txt\"\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(\"UNKNOWN DATASET - PREDICTION RESULTS\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        f.write(f\"\\n{'=' * 80}\\n\")\n",
    "        f.write(f\"FILE {i}: {result['filename']}\\n\")\n",
    "        f.write('=' * 80 + \"\\n\")\n",
    "        f.write(f\"Expected (from filename): {result['expected'].upper()}\\n\")\n",
    "        \n",
    "        if result['status'] == 'SUCCESS':\n",
    "            f.write(f\"PREDICTED EMOTION: {result['predicted_emotion'].upper()}\\n\")\n",
    "            f.write(f\"CONFIDENCE: {result['confidence']:.2f}%\\n\")\n",
    "            f.write(f\"RESULT: {'‚úÖ CORRECT' if result['correct'] else '‚ùå WRONG'}\\n\")\n",
    "            f.write(f\"\\nALL PROBABILITIES:\\n\")\n",
    "            sorted_probs = sorted(result['all_probabilities'].items(), key=lambda x: x[1], reverse=True)\n",
    "            for emotion, prob in sorted_probs:\n",
    "                f.write(f\"  {emotion.capitalize():12s}: {prob*100:6.2f}%\\n\")\n",
    "        else:\n",
    "            f.write(f\"STATUS: {result['status']}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    # Summary\n",
    "    f.write(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "    f.write(\"SUMMARY\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(f\"Total files tested: {len(results)}\\n\")\n",
    "    f.write(f\"Successful predictions: {len(successful)}\\n\")\n",
    "    f.write(f\"Correct predictions: {len(correct_predictions)}/{len(successful)}\\n\")\n",
    "    f.write(f\"Wrong predictions: {len(wrong_predictions)}/{len(successful)}\\n\")\n",
    "    if len(successful) > 0:\n",
    "        f.write(f\"Accuracy: {(len(correct_predictions) / len(successful)) * 100:.2f}%\\n\")\n",
    "\n",
    "print(f\"‚úÖ Results saved to: {output_file}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# FINAL MESSAGE\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéâ TESTING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if len(successful) > 0:\n",
    "    if len(correct_predictions) == len(successful):\n",
    "        print(\"\\nüéâüéâüéâ PERFECT! The model got ALL predictions correct!\")\n",
    "    elif len(correct_predictions) > 0:\n",
    "        print(f\"\\n‚úÖ Model got {len(correct_predictions)}/{len(successful)} correct\")\n",
    "        print(f\"‚ùå Model got {len(wrong_predictions)}/{len(successful)} wrong\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå The model got all predictions wrong\")\n",
    "        print(\"   This might indicate the model needs more training or the audio is very different from training data\")\n",
    "\n",
    "print(f\"\\nüíæ Detailed results saved to: {output_file}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9346393,
     "sourceId": 14631448,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
